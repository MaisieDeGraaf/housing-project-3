{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e914c081-0e71-4c76-88e7-de28f07174b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T23:32:56.934967Z",
     "start_time": "2024-02-28T23:32:56.920424Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'api_keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# %run api_keys.py\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mapi_keys\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m email, passw, mongo_username_scraper, mongo_password_scraper\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'api_keys'"
     ]
    }
   ],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "# %run api_keys.py\n",
    "from api_keys import email, passw, mongo_username_scraper, mongo_password_scraper #Please add to .gitnore file your own individual usernames and passwords. Also set up your account on the website with a watched area of your desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2624ae5-31c0-422b-b528-8dd78ba3f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to website\n",
    "browser = Browser('chrome')\n",
    "url = \"https://housesigma.com/listings/watched-area-and-community\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup_obj = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2429942ca8a96d4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign variables and Login\n",
    "browser.execute_script('document.querySelector(\".app-btn.round.regular.pressed-down.btn\").click();')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ac566-185f-49f0-b406-82e2df1b8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_input = WebDriverWait(browser.driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, '.form-input.medium.clear.input input[type=\"email\"]'))\n",
    ")\n",
    "email = email\n",
    "passw = passw\n",
    "login = email\n",
    "email_input.send_keys(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed498b02-96ec-420b-a1d5-a639465d3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "password_input = WebDriverWait(browser.driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, '.form-input.medium.clear.input input[type=\"password\"]'))\n",
    ")\n",
    "password = passw \n",
    "password_input.send_keys(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5310777-f6cb-4425-b893-fc920aa42c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = browser.find_by_css('.app-btn.hs_btn_login_submit_email').first\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e5594-78dd-425e-a241-d65144dafe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.is_element_present_by_css('.pc-listing-card', wait_time=10)\n",
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cea95-654b-4547-884f-8ceee5e86396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list to store data\n",
    "data_list = []\n",
    "\n",
    "# Max 10 pages @todo: change to 10.\n",
    "num_scrolls = 2\n",
    "\n",
    "# Scrape the site\n",
    "for _ in range(num_scrolls):\n",
    "\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    html = browser.html\n",
    "    \n",
    "    articles = soup_obj.find_all('article', class_='pc-listing-card')\n",
    "\n",
    "    for article in articles:\n",
    "        data = {}\n",
    "\n",
    "    # Address\n",
    "        address_element = article.find('h3', class_='address')\n",
    "        data['Address'] = address_element.text.strip() if address_element else None\n",
    "\n",
    "    # Neighbourhood\n",
    "        text1_element = article.find('span', class_='text1')\n",
    "        data['Neighbourhood'] = text1_element.text.strip() if text1_element else None\n",
    "\n",
    "        json_scripts = article.find_all('script', class_='hs-script-home-struct', type='application/ld+json')\n",
    "\n",
    "\n",
    "        for script in json_scripts:\n",
    "            json_data = script.string\n",
    "            if json_data:\n",
    "                json_dict = json.loads(json_data)\n",
    "            \n",
    "            # Long and Lat and floor size\n",
    "                if 'floorSize' in json_dict:\n",
    "                    data['Floor Size'] = json_dict['floorSize']['value']\n",
    "                if 'geo' in json_dict:\n",
    "                    data['Latitude'] = json_dict['geo']['latitude']\n",
    "                    data['Longitude'] = json_dict['geo']['longitude']\n",
    "\n",
    "    # Date \n",
    "        date_preview_element = article.find('div', class_='date-preview')\n",
    "        data['Date of Status'] = date_preview_element.text.strip() if date_preview_element else None\n",
    "\n",
    "    # Price\n",
    "        highlight_element = article.find('span', class_='highlight')\n",
    "        line_through_element = article.find('span', class_='line-through')\n",
    "\n",
    "        if highlight_element:\n",
    "            data['Price Listed'] = highlight_element.text.strip()\n",
    "        elif line_through_element:\n",
    "            data['Price Listed'] = line_through_element.text.strip()\n",
    "        else:\n",
    "            data['Price Listed'] = None\n",
    "   \n",
    "    # Status\n",
    "        status_element = article.select_one('div[class^=\"status-type\"]')\n",
    "        data['Status'] = status_element.text.strip() if status_element else None\n",
    "\n",
    "    # Sold Price (if status is \"Sold\" or \"Sold Conditional\")\n",
    "        if data['Status'] in [\"Sold\", \"Sold Conditional\"]:\n",
    "            sold_price_element_special = article.select_one('div.price-area span.special')\n",
    "            sold_price_element_highlight_special = article.select_one('div.price-area span.highlight.special')\n",
    "\n",
    "            if sold_price_element_special:\n",
    "                data['Sold Price'] = sold_price_element_special.text.strip()\n",
    "            elif sold_price_element_highlight_special:\n",
    "                data['Sold Price'] = sold_price_element_highlight_special.text.strip()\n",
    "            else:\n",
    "                data['Sold Price'] = None\n",
    "        else:\n",
    "            data['Sold Price'] = 0\n",
    "    \n",
    "    # Type of house\n",
    "        type_element = article.find('p', class_='type')\n",
    "        data['Type of House'] = type_element.text.strip() if type_element else None\n",
    "\n",
    "        p_elements = article.find_all('p')\n",
    "        for p in p_elements:\n",
    "            text = p.get_text()\n",
    "\n",
    "        # Bathroom\n",
    "            if re.search(r'\\b(?:bathroom)\\b', text):\n",
    "                bathroom_info = re.findall(r'\\d+', text)\n",
    "                if bathroom_info:\n",
    "                    data['Bathrooms'] = int(bathroom_info[0])\n",
    "\n",
    "        # Bedroom\n",
    "            if re.search(r'\\b(?:bedroom)\\b', text):\n",
    "                bedroom_info = re.findall(r'\\d+', text)\n",
    "                if bedroom_info:\n",
    "                    data['Bedrooms'] = int(bedroom_info[0])\n",
    "        \n",
    "        # Garage\n",
    "            if re.search(r'\\b(?:garage)\\b', text):\n",
    "                garage_info = re.findall(r'\\d+', text)\n",
    "                if garage_info:\n",
    "                    data['Garage'] = int(garage_info[0]) \n",
    "                \n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_list, 1):\n",
    "    print(f\"{i}: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cabdf-16dd-43a7-bb28-4838a0bbfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean scraped data\n",
    "def convert_relative_timestamp(relative_timestamp):\n",
    "    if \" hours ago\" in relative_timestamp:\n",
    "        hours = int(relative_timestamp.split()[0])\n",
    "        absolute_timestamp = datetime.now() - timedelta(hours=hours)\n",
    "        return absolute_timestamp.date()\n",
    "    elif \" days ago\" in relative_timestamp:\n",
    "        days = int(relative_timestamp.split()[0])\n",
    "        absolute_timestamp = datetime.now() - timedelta(days=days)\n",
    "        return absolute_timestamp.date()\n",
    "    else:\n",
    "        return datetime.now().date()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df['City'] = df['Address'].str.split(',').str[1].str.split(' - ').str[0]\n",
    "df['Address'] = df['Address'].str.split(',').str[0]\n",
    "df['Date of Status'] = df['Date of Status'].apply(convert_relative_timestamp)\n",
    "\n",
    "df['Sold Price'] = pd.to_numeric(df['Sold Price'].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "df['Price Listed'] = pd.to_numeric(df['Price Listed'].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Replace '-' with NaN in 'Price Listed' column\n",
    "df['Price Listed'].replace('-', np.nan, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccf3d8-ba02-4dda-9b6f-92a0be216e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare weather data from specified csv\n",
    "weather_data_oakville = 'Resources/Oakville_Historical_Weather.csv'\n",
    "selected_columns = ['HEATING_DEGREE_DAYS', 'MIN_TEMPERATURE','LOCAL_DATE', 'STATION_NAME', 'COOLING_DEGREE_DAYS', 'LOCAL_MONTH', 'LOCAL_DAY', 'LOCAL_YEAR', 'TOTAL_PRECIPITATION', 'SNOW_ON_GROUND', 'MEAN_TEMPERATURE', 'TOTAL_SNOW', 'TOTAL_RAIN', 'MAX_TEMPERATURE', 'ID']\n",
    "df_weather = pd.read_csv(weather_data_oakville, usecols=selected_columns, encoding=\"ISO-8859-1\", on_bad_lines='skip', low_memory=True, engine='python')\n",
    "df_weather = df_weather.dropna(subset=['MIN_TEMPERATURE'])\n",
    "df_weather = df_weather.reset_index(drop=True)\n",
    "columns_to_fill = ['HEATING_DEGREE_DAYS', 'MIN_TEMPERATURE', 'COOLING_DEGREE_DAYS', \n",
    "                   'TOTAL_PRECIPITATION', 'SNOW_ON_GROUND', 'MEAN_TEMPERATURE', \n",
    "                   'TOTAL_SNOW', 'TOTAL_RAIN', 'MAX_TEMPERATURE']\n",
    "df_weather[columns_to_fill] = df_weather[columns_to_fill].fillna(0)\n",
    "df_weather['LOCAL_DATE'] = pd.to_datetime(df_weather['LOCAL_DATE']).dt.date\n",
    "df_weather.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef765cbff89189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to Mongo @todo: move credentials to different doc.... \n",
    "# mongo_client = pymongo.MongoClient('mongodb+srv://jaylene:emv7qzy.ZWM1nta9qbv@cluster0.9gjuly6.mongodb.net/')\n",
    "\n",
    "# MongoDB connection string\n",
    "mongo_connection_string = f'mongodb+srv://{mongo_username_scraper}:{mongo_password_scraper}@cluster0.9gjuly6.mongodb.net/'\n",
    "\n",
    "# Connect to MongoDB\n",
    "mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "\n",
    "# Create DB\n",
    "mongo_db = mongo_client.properties\n",
    "\n",
    "# Insert data into separate collections\n",
    "house_collection = mongo_db.houses\n",
    "sold_collection = mongo_db.sold\n",
    "weather_collection = mongo_db.weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e0a76-3648-4f23-809c-8aa3deed91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data_list into MongoDB\n",
    "for data in data_list:\n",
    "    address = data.get('Address')\n",
    "    if address:\n",
    "        house_exists = house_collection.find_one({'address': address})\n",
    "\n",
    "    if house_exists:\n",
    "        house_collection.update_one(\n",
    "            {'address': address},\n",
    "            {\n",
    "                '$set': {\n",
    "                    'status': data.get('Status'),\n",
    "                    'date_listed': convert_relative_timestamp(data.get('Date of Status'))\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        address_parts = address.split(',')\n",
    "        city = address_parts[1].split(' - ')[0].strip()\n",
    "        address = address_parts[0]\n",
    "\n",
    "        new_house = {\n",
    "            'address': address,\n",
    "            'status': data.get('Status'),\n",
    "            'latitude': data.get('Latitude'),\n",
    "            'longitude': data.get('Longitude'),\n",
    "            'floor_size': data.get('Floor Size'),\n",
    "            'bedrooms': data.get('Bedrooms'),\n",
    "            'bathrooms': data.get('Bathrooms'),\n",
    "            'garage': data.get('Garage'),\n",
    "            'city': city,\n",
    "            'type_of_house': data.get('Type of House'),\n",
    "            'date_listed': convert_relative_timestamp(data.get('Date of Status')),\n",
    "            'neighbourhood': data.get('Neighbourhood'),\n",
    "            'price': float(data.get('Price Listed').replace('$', '').replace(',', ''))\n",
    "        }\n",
    "\n",
    "        house_collection.insert_one(new_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51f3ea-b612-4633-8379-18862ba267b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    address = data.get('Address')\n",
    "    status = data.get('Status')\n",
    "\n",
    "    if status in [\"Sold\", \"Sold Conditional\"]:\n",
    "        sold_house = sold_collection.find_one({'address': address})\n",
    "\n",
    "        if sold_house:\n",
    "            sold_collection.update_one(\n",
    "                {'address': address},\n",
    "                {\n",
    "                    '$set': {\n",
    "                        'status': status,\n",
    "                        'date_listed': convert_relative_timestamp(data.get('Date of Status')),\n",
    "                        'sold_price': float(str(data.get('Sold Price')).replace('$', '').replace(',', ''))\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            address_parts = address.split(',')\n",
    "            city = address_parts[1].split(' - ')[0].strip()\n",
    "            address = address_parts[0]\n",
    "            new_sold_house = {\n",
    "                'address': address,\n",
    "                'price': float(data.get('Price Listed').replace('$', '').replace(',', '')),\n",
    "                'status': status,\n",
    "                'date_listed': convert_relative_timestamp(data.get('Date of Status')),\n",
    "                'sold_price': float(str(data.get('Sold Price')).replace('$', '').replace(',', '')),\n",
    "                'city': city,\n",
    "                'type_of_house': data.get('Type of House'),\n",
    "                'neighbourhood': data.get('Neighbourhood')\n",
    "            }\n",
    "\n",
    "            sold_collection.insert_one(new_sold_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c4876-aa00-4f22-ae49-07dc150cbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_weather.iterrows():\n",
    "    weather_data_instance = {\n",
    "        'id': row['ID'],\n",
    "        'heating_degree_days': row['HEATING_DEGREE_DAYS'],\n",
    "        'min_temperature': row['MIN_TEMPERATURE'],\n",
    "        'local_date': row['LOCAL_DATE'],\n",
    "        'station_name': row['STATION_NAME'],\n",
    "        'cooling_degree_days': row['COOLING_DEGREE_DAYS'],\n",
    "        'local_month': row['LOCAL_MONTH'],\n",
    "        'local_day': row['LOCAL_DAY'],\n",
    "        'local_year': row['LOCAL_YEAR'],\n",
    "        'total_precipitation': row['TOTAL_PRECIPITATION'],\n",
    "        'snow_on_ground': row['SNOW_ON_GROUND'],\n",
    "        'mean_temperature': row['MEAN_TEMPERATURE'],\n",
    "        'total_snow': row['TOTAL_SNOW'],\n",
    "        'total_rain': row['TOTAL_RAIN'],\n",
    "        'max_temperature': row['MAX_TEMPERATURE']\n",
    "    }\n",
    "\n",
    "    weather_collection.insert_one(weather_data_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0c444-7972-41a5-aec8-17a9466fd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of records for each collection\n",
    "weather_count = mongo_db.weather_data.count_documents({})\n",
    "sold_count = mongo_db.sold.count_documents({})\n",
    "house_count = mongo_db.houses.count_documents({})\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of records in WeatherData collection:\", weather_count)\n",
    "print(\"Number of records in Sold collection:\", sold_count)\n",
    "print(\"Number of records in House collection:\", house_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ec971-706f-4ed0-aaf0-2b7f3e004eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa59b-573b-4e77-9cdb-6b51c0d8785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close browser\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
